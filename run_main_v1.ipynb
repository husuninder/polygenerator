{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa8bfa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e0bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfba3709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shapely\n",
      "  Downloading shapely-2.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/codespace/.local/lib/python3.12/site-packages (from shapely) (2.3.1)\n",
      "Downloading shapely-2.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shapely\n",
      "Successfully installed shapely-2.1.2\n"
     ]
    }
   ],
   "source": [
    "# Install the required packages\n",
    "! pip install shapely "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8dd2263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Initializing Scene Setup...\n",
      "🗺️  Environment created with 12 vertices.\n",
      "🏃 Generating 2 tracked objects...\n",
      "  -> 🎯 TrackedObject ID 0 created with a path of 15 steps.\n",
      "  -> 🎯 TrackedObject ID 1 created with a path of 15 steps.\n",
      "🎥 Placing 3 cameras...\n",
      "  -> 📷 Camera created at (0.58, 0.68).\n",
      "  -> 📷 Camera created at (0.17, 0.56).\n",
      "  -> 📷 Camera created at (0.87, 0.54).\n",
      "✅ Scene setup complete!\n",
      "\n",
      "🎬 Running simulation for 15 time steps...\n",
      "  -> 🖼️  Generating frame 0... Visibility Scores: {0: 6, 1: 13}\n",
      "  -> 🖼️  Generating frame 1... Visibility Scores: {0: 8, 1: 7}\n",
      "  -> 🖼️  Generating frame 2... Visibility Scores: {0: 14, 1: 5}\n",
      "  -> 🖼️  Generating frame 3... Visibility Scores: {0: 13, 1: 6}\n",
      "  -> 🖼️  Generating frame 4... Visibility Scores: {0: 9, 1: 22}\n",
      "  -> 🖼️  Generating frame 5... Visibility Scores: {0: 7, 1: 22}\n",
      "  -> 🖼️  Generating frame 6... Visibility Scores: {0: 12, 1: 7}\n",
      "  -> 🖼️  Generating frame 7... Visibility Scores: {0: 13, 1: 15}\n",
      "  -> 🖼️  Generating frame 8... Visibility Scores: {0: 14, 1: 6}\n",
      "  -> 🖼️  Generating frame 9... Visibility Scores: {0: 13, 1: 7}\n",
      "  -> 🖼️  Generating frame 10... Visibility Scores: {0: 14, 1: 5}\n",
      "  -> 🖼️  Generating frame 11... Visibility Scores: {0: 16, 1: 9}\n",
      "  -> 🖼️  Generating frame 12... Visibility Scores: {0: 10, 1: 10}\n",
      "  -> 🖼️  Generating frame 13... Visibility Scores: {0: 5, 1: 11}\n",
      "  -> 🖼️  Generating frame 14... Visibility Scores: {0: 9, 1: 14}\n",
      "\n",
      "✅ Simulation complete! 15 frames saved to 'simulation_centered_text'.\n"
     ]
    }
   ],
   "source": [
    "## Import Packages\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon, LineString, box\n",
    "from shapely.affinity import rotate\n",
    "import matplotlib.pyplot as plt\n",
    "from polygenerator import random_convex_polygon\n",
    "\n",
    "# --- Core Modules (Classes) ---\n",
    "\n",
    "class Environment:\n",
    "    \"\"\"\n",
    "    Defines the simulation environment, which is a polygonal boundary.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_vertices=12):\n",
    "        self.polygon_coords = random_convex_polygon(n_vertices)\n",
    "        self.polygon = Polygon(self.polygon_coords)\n",
    "        if not self.polygon.is_valid:\n",
    "            raise ValueError(\"The generated polygon is invalid.\")\n",
    "        print(f\"🗺️  Environment created with {n_vertices} vertices.\")\n",
    "\n",
    "    def get_bounds(self):\n",
    "        return self.polygon.bounds\n",
    "\n",
    "class TrackedObject:\n",
    "    \"\"\"\n",
    "    Represents an object that moves along a path within the environment.\n",
    "    \"\"\"\n",
    "    def __init__(self, environment_polygon, object_id, n_waypoints=5, short_side_length=0.05, seed=None):\n",
    "        self.id = object_id\n",
    "        self.env_poly = environment_polygon\n",
    "        self.n_waypoints = n_waypoints\n",
    "        self.short_side = short_side_length\n",
    "        self.long_side = 4 * self.short_side\n",
    "        self.seed = seed\n",
    "        self.waypoints = []\n",
    "        self.path = []\n",
    "        self.shapes = []\n",
    "        self._generate_path()\n",
    "        self._create_shapes()\n",
    "        print(f\"  -> 🎯 TrackedObject ID {self.id} created with a path of {n_waypoints} steps.\")\n",
    "\n",
    "    def _generate_path(self):\n",
    "        if self.seed is not None:\n",
    "            random.seed(self.seed)\n",
    "            np.random.seed(self.seed)\n",
    "        half_short = self.short_side / 2.0\n",
    "        half_long = self.long_side / 2.0\n",
    "        margin = np.sqrt(half_long**2 + half_short**2)\n",
    "        safe_sampling_area = self.env_poly.buffer(-margin)\n",
    "        if safe_sampling_area.is_empty:\n",
    "            raise ValueError(\"Object size is too large for the environment.\")\n",
    "        minx, miny, maxx, maxy = safe_sampling_area.bounds\n",
    "        while len(self.waypoints) < self.n_waypoints:\n",
    "            point = Point(random.uniform(minx, maxx), random.uniform(miny, maxy))\n",
    "            if safe_sampling_area.contains(point):\n",
    "                self.waypoints.append(point)\n",
    "        pts_arr = np.array([(p.x, p.y) for p in self.waypoints])\n",
    "        dist_matrix = np.sqrt(np.sum((pts_arr[:, np.newaxis, :] - pts_arr[np.newaxis, :, :])**2, axis=-1))\n",
    "        unvisited = set(range(self.n_waypoints))\n",
    "        path_indices = [0]\n",
    "        unvisited.remove(0)\n",
    "        while unvisited:\n",
    "            last_idx = path_indices[-1]\n",
    "            next_idx = min(unvisited, key=lambda i: dist_matrix[last_idx, i])\n",
    "            path_indices.append(next_idx)\n",
    "            unvisited.remove(next_idx)\n",
    "        self.path = [self.waypoints[i] for i in path_indices]\n",
    "\n",
    "    def _create_shapes(self):\n",
    "        half_short = self.short_side / 2.0\n",
    "        half_long = self.long_side / 2.0\n",
    "        for point in self.path:\n",
    "            rectangle = box(-half_long, -half_short, half_long, half_short)\n",
    "            rotated_rectangle = rotate(rectangle, random.uniform(0, 360), origin='center')\n",
    "            moved_rectangle = Polygon([(p[0] + point.x, p[1] + point.y) for p in rotated_rectangle.exterior.coords])\n",
    "            self.shapes.append(moved_rectangle)\n",
    "\n",
    "class Camera:\n",
    "    \"\"\"\n",
    "    Represents a camera sensor. Identifies *which* object was hit.\n",
    "    \"\"\"\n",
    "    def __init__(self, position, camera_range=3.0, n_rays=36):\n",
    "        self.position = position\n",
    "        self.range = camera_range\n",
    "        self.n_rays = n_rays\n",
    "        self.rays = []\n",
    "        print(f\"  -> 📷 Camera created at ({position.x:.2f}, {position.y:.2f}).\")\n",
    "\n",
    "    def cast_rays(self, environment_polygon, obstacles):\n",
    "        \"\"\"Casts rays, storing the ID of the hit object.\"\"\"\n",
    "        self.rays = []\n",
    "        angles = np.linspace(0, 360, self.n_rays, endpoint=False)\n",
    "        all_boundaries = obstacles + [environment_polygon.boundary]\n",
    "        for angle in angles:\n",
    "            end_x = self.position.x + self.range * np.cos(np.radians(angle))\n",
    "            end_y = self.position.y + self.range * np.sin(np.radians(angle))\n",
    "            ray = LineString([self.position, (end_x, end_y)])\n",
    "            intersection_points = []\n",
    "            for boundary in all_boundaries:\n",
    "                if ray.intersects(boundary):\n",
    "                    intersection = ray.intersection(boundary)\n",
    "                    if hasattr(intersection, 'geoms'):\n",
    "                        for geom in intersection.geoms:\n",
    "                            if geom.geom_type == 'Point':\n",
    "                                intersection_points.append(geom)\n",
    "                            elif geom.geom_type == 'LineString':\n",
    "                                intersection_points.append(Point(geom.coords[0]))\n",
    "                    elif not intersection.is_empty:\n",
    "                        if intersection.geom_type == 'Point':\n",
    "                            intersection_points.append(intersection)\n",
    "                        elif intersection.geom_type == 'LineString':\n",
    "                            intersection_points.append(Point(intersection.coords[0]))\n",
    "            end_point = ray.coords[1]\n",
    "            hit_id = None\n",
    "            if intersection_points:\n",
    "                closest_point = min(intersection_points, key=lambda p: self.position.distance(p))\n",
    "                end_point = closest_point.coords[0]\n",
    "                for i, obs in enumerate(obstacles):\n",
    "                    if obs.distance(closest_point) < 1e-9:\n",
    "                        hit_id = i\n",
    "                        break\n",
    "            self.rays.append([self.position.coords[0], end_point, hit_id])\n",
    "\n",
    "class Scene:\n",
    "    \"\"\"\n",
    "    Manages the setup of the simulation and updates its state over time.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_objects=2, n_waypoints=10, n_cameras=3, seed=42):\n",
    "        print(\"🚀 Initializing Scene Setup...\")\n",
    "        self.env = Environment()\n",
    "        self.objects = []\n",
    "        self.cameras = []\n",
    "        self.seed = seed\n",
    "        self.num_timesteps = n_waypoints\n",
    "        \n",
    "        self._generate_objects(n_objects, n_waypoints)\n",
    "        self._place_cameras(n_cameras)\n",
    "        print(\"✅ Scene setup complete!\")\n",
    "        \n",
    "    def _generate_objects(self, n_objects, n_waypoints):\n",
    "        print(f\"🏃 Generating {n_objects} tracked objects...\")\n",
    "        for i in range(n_objects):\n",
    "            obj_seed = self.seed + i if self.seed is not None else None\n",
    "            obj = TrackedObject(self.env.polygon, object_id=i, n_waypoints=n_waypoints, seed=obj_seed)\n",
    "            self.objects.append(obj)\n",
    "            \n",
    "    def _place_cameras(self, n_cameras):\n",
    "        print(f\"🎥 Placing {n_cameras} cameras...\")\n",
    "        if self.seed is not None:\n",
    "            random.seed(self.seed + 100)\n",
    "        all_future_obstacles = [shape for obj in self.objects for shape in obj.shapes]\n",
    "        minx, miny, maxx, maxy = self.env.get_bounds()\n",
    "        while len(self.cameras) < n_cameras:\n",
    "            point = Point(random.uniform(minx, maxx), random.uniform(miny, maxy))\n",
    "            is_in_env = self.env.polygon.contains(point)\n",
    "            is_on_obstacle = any(obs.contains(point) for obs in all_future_obstacles)\n",
    "            if is_in_env and not is_on_obstacle:\n",
    "                self.cameras.append(Camera(point))\n",
    "\n",
    "    def update_scene_at_timestep(self, time_step):\n",
    "        if not (0 <= time_step < self.num_timesteps):\n",
    "            print(f\"⚠️ Warning: Time step {time_step} is out of bounds.\")\n",
    "            return\n",
    "        current_obstacles = [obj.shapes[time_step] for obj in self.objects]\n",
    "        for cam in self.cameras:\n",
    "            cam.cast_rays(self.env.polygon, current_obstacles)\n",
    "\n",
    "class VisibilityCalculator:\n",
    "    \"\"\"\n",
    "    Calculates visibility scores for objects in the scene.\n",
    "    \"\"\"\n",
    "    def __init__(self, scene):\n",
    "        self.scene = scene\n",
    "\n",
    "    def calculate_at_timestep(self):\n",
    "        \"\"\"Counts the number of rays from all cameras hitting each object.\"\"\"\n",
    "        scores = {obj.id: 0 for obj in self.scene.objects}\n",
    "        all_rays = [ray for cam in self.scene.cameras for ray in cam.rays]\n",
    "        for ray in all_rays:\n",
    "            hit_id = ray[2]\n",
    "            if hit_id is not None:\n",
    "                scores[hit_id] += 1\n",
    "        return scores\n",
    "\n",
    "class Visualizer:\n",
    "    def __init__(self, scene):\n",
    "        self.scene = scene\n",
    "    \n",
    "    def plot_timestep(self, time_step, visibility_scores, save_fig=False, output_dir=\".\"):\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        object_colors = ['#FF1493', '#00BFFF', '#32CD32', '#FFD700', '#9400D3', '#FF4500']\n",
    "        \n",
    "        # Plot Environment\n",
    "        x, y = self.scene.env.polygon.exterior.xy\n",
    "        ax.plot(x, y, color='black', linewidth=2, label='Environment Boundary')\n",
    "        \n",
    "        # Plot Tracked Objects\n",
    "        for i, obj in enumerate(self.scene.objects):\n",
    "            primary_color_hex = object_colors[i % len(object_colors)]\n",
    "            \n",
    "            # Plot the simple path for context\n",
    "            path_x = [p.x for p in obj.path]\n",
    "            path_y = [p.y for p in obj.path]\n",
    "            ax.plot(path_x, path_y, 'o--', color=primary_color_hex, markersize=5, alpha=0.3)\n",
    "\n",
    "            # Plot the object's current position\n",
    "            current_shape = obj.shapes[time_step]\n",
    "            sx, sy = current_shape.exterior.xy\n",
    "            ax.fill(sx, sy, alpha=0.9, color=primary_color_hex, label=f'Object {i+1} Position')\n",
    "\n",
    "            # *** START OF CHANGE ***\n",
    "            # 1. Get the geometric center (centroid) of the object\n",
    "            centroid = current_shape.centroid\n",
    "            \n",
    "            # 2. Get the score\n",
    "            score = visibility_scores.get(obj.id, 0)\n",
    "            \n",
    "            # 3. Display the text right on the centroid\n",
    "            ax.text(centroid.x, centroid.y, f\"Hits: {score}\",\n",
    "                    ha='center', va='center', # Center the text block on the point\n",
    "                    fontweight='bold', fontsize=9,\n",
    "                    color='white',\n",
    "                    bbox=dict(boxstyle='round,pad=0.2', fc='black', alpha=0.5),\n",
    "                    zorder=100)\n",
    "            # *** END OF CHANGE ***\n",
    "\n",
    "        # Plot Cameras and their current rays\n",
    "        for cam in self.scene.cameras:\n",
    "            ax.plot(cam.position.x, cam.position.y, 'ro', markersize=8, label='Camera')\n",
    "            for ray in cam.rays:\n",
    "                start, end, hit_id = ray\n",
    "                ray_color = 'red' if hit_id is not None else 'cyan'\n",
    "                line = LineString([start, end])\n",
    "                lx, ly = line.xy\n",
    "                ax.plot(lx, ly, color=ray_color, linewidth=0.7)\n",
    "\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.set_title(f\"Simulation at Time Step: {time_step}\", fontsize=16)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        ax.legend(by_label.values(), by_label.keys())\n",
    "        \n",
    "        if save_fig:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            filepath = os.path.join(output_dir, f\"timestep_{time_step:03d}.png\")\n",
    "            plt.savefig(filepath)\n",
    "            plt.close(fig)\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    SAVE_PLOTS = True\n",
    "    OUTPUT_DIRECTORY = \"simulation_centered_text\"\n",
    "    NUMBER_OF_TIMESTEPS = 15\n",
    "\n",
    "    simulation_scene = Scene(n_objects=2, n_waypoints=NUMBER_OF_TIMESTEPS, n_cameras=3, seed=42)\n",
    "    visualizer = Visualizer(simulation_scene)\n",
    "    calculator = VisibilityCalculator(simulation_scene)\n",
    "\n",
    "    print(f\"\\n🎬 Running simulation for {NUMBER_OF_TIMESTEPS} time steps...\")\n",
    "\n",
    "    for t in range(simulation_scene.num_timesteps):\n",
    "        simulation_scene.update_scene_at_timestep(t)\n",
    "        visibility_scores = calculator.calculate_at_timestep()\n",
    "        print(f\"  -> 🖼️  Generating frame {t}... Visibility Scores: {visibility_scores}\")\n",
    "        visualizer.plot_timestep(t, visibility_scores=visibility_scores, save_fig=SAVE_PLOTS, output_dir=OUTPUT_DIRECTORY)\n",
    "    \n",
    "    if SAVE_PLOTS:\n",
    "        print(f\"\\n✅ Simulation complete! {simulation_scene.num_timesteps} frames saved to '{OUTPUT_DIRECTORY}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8da6b6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from opencv-python-headless) (2.2.6)\n",
      "Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.12.0.88\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python-headless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b2f944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎬 Creating video from images in 'simulation_centered_text'...\n",
      "✅ Video saved successfully to 'simulation_video.mp4'\n"
     ]
    }
   ],
   "source": [
    "## Make the images from simulation_centered_text into a video with 1 second per image. \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "def create_video_from_images(image_folder, output_video_path, fps=1):\n",
    "    \"\"\"\n",
    "    Creates a video from a sequence of images in a folder.\n",
    "\n",
    "    Args:\n",
    "        image_folder (str): Path to the folder containing the images.\n",
    "        output_video_path (str): Path to save the output video file (e.g., 'simulation.mp4').\n",
    "        fps (int): Frames per second for the video.\n",
    "    \"\"\"\n",
    "    print(f\"🎬 Creating video from images in '{image_folder}'...\")\n",
    "    \n",
    "    # Get all image files and sort them naturally to handle numbers correctly\n",
    "    # (e.g., timestep_1.png, timestep_2.png, ..., timestep_10.png)\n",
    "    images = sorted(glob.glob(os.path.join(image_folder, '*.png')), \n",
    "                    key=lambda x: int(os.path.basename(x).split('_')[1].split('.')[0]))\n",
    "\n",
    "    if not images:\n",
    "        print(f\"⚠️ No .png images found in the directory '{image_folder}'. Video creation aborted.\")\n",
    "        return\n",
    "\n",
    "    # Read the first image to get the frame size\n",
    "    frame = cv2.imread(images[0])\n",
    "    height, width, layers = frame.shape\n",
    "    size = (width, height)\n",
    "\n",
    "    # Initialize the video writer\n",
    "    # The 'mp4v' codec is a good choice for .mp4 files.\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, size)\n",
    "\n",
    "    # Loop through all images and write them to the video\n",
    "    for image_path in images:\n",
    "        frame = cv2.imread(image_path)\n",
    "        out.write(frame)\n",
    "\n",
    "    # Release the video writer to save the file\n",
    "    out.release()\n",
    "    print(f\"✅ Video saved successfully to '{output_video_path}'\")\n",
    "    \n",
    "# --- Configuration ---\n",
    "# Make sure this matches the output directory from your simulation\n",
    "IMAGE_DIRECTORY = \"simulation_centered_text\" \n",
    "VIDEO_FILENAME = \"simulation_video.mp4\"\n",
    "VIDEO_FPS = 1 # 1 frame per second\n",
    "\n",
    "# --- Call the function to create the video ---\n",
    "create_video_from_images(\n",
    "    image_folder=IMAGE_DIRECTORY, \n",
    "    output_video_path=VIDEO_FILENAME, \n",
    "    fps=VIDEO_FPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07417852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
